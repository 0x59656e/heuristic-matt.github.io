{"pages":[],"posts":[{"title":"An Excursion of Linux: Job and Process Management","text":"Background KnowledgeMain Components User Processes: GUI, Servers, Shell, etc. Linux Kernel: System Calls, Process Management, Memory Management, Device Drivers Hardware: Processor (CPU), Main Memory (RAM), Disks, Network Ports Process Management: starting, pausing, resuming, and terminating A job of memory management by the kernel: The kernel must have its own private area in memory that user processes can’t access. Each user process needs its own section of memory. One user process may not access the private memory of others. User processes can share memory. Some memory in user processes can be read-only. The system can use more memory than is physically present by using disk space as auxiliary (swap). Modern CPUs include a memory management unit (MMU) that enables a memory access scheme called virtual memory. What does MMU do when the process accesses the memory? The MMU intercepts the access and uses a memory address map to translate the memory location from the process into an actual physical memory location on the machine. The kernel must still initialize and continuously maintain and alter this memory address map. The implementation of a memory address map is called a page table. Two important system calls about how processes start up fork() When a process calls fork(), the kernel creates a nearly identical copy of the process. exec() When a process calls exec(), the kernel starts the program, replacing the current process. The general procedure of starting a new process 12shell -&gt; fork() -&gt; shell -&gt; copy of shell -&gt; exec() -&gt; program ps : report a snapshot of the current processes.Commonly, we use ps in BSD style and with grep to narrow down the result. Options: ax: list all processes. u: show detailed information with columns USER, PID, CPU, MEM, VSZ, RSS, TTY, STAT, START, TIME, COMMAND w: width output, use twice for unlimited width. Process State Code (From man ps) D: uninterruptible sleep (usually IO) R: running or runnable (on run queue) S: interruptible sleep (waiting for an event to complete) T: stopped, either by a job control signal or because it is being traced W: paging (not valid since the 2.6.xx kernel) X: dead (should never be seen) Z: defunct (“zombie”) process, terminated but not reaped by its parent For BSD formats and when the stat keyword is used, additional characters may be displayed: &lt;: high-priority (not nice to other users) N: low-priority (nice to other users) L: has pages locked into memory (for real-time and custom IO) s: is a session leader l: is multi-threaded (using CLONE_THREAD, like NPTL pthreads do) +: is in the foreground process group Examples: ps aux: list every process ps auxww: the same as above, but including the full command string. ps axjf: show process tree ps aux | grep '[s]ome-program': to exclude the grep process for this filtering. kill : send a signal to a processTo terminate a process, send it a signal with the kill command. The default is TERM, or terminate: kill PID To freeze a process instead of terminating it, use the STOP signal: kill -STOP PID Use the CONT signal to continue running the process again: kill -CONT PID Terminates the process and forcibly removes it from memory: kill -KILL PID Job ControlCTRL + Z: send a TSTP signal, which is similar to STOP. fg JOB_ID: bring the job to foreground. bg JOB_ID: let the job run in the background. jobs: Display status of jobs in the current session. Show status and process IDs of all jobs: jobs -l command &amp;: detach a process from the shell and put it in the “background.” The process will continue to run after you log out. If a program tries to read something from the standard input when it’s in the background, it can freeze (try fg to bring it back) or terminate. Make sure that a background process doesn’t bother you is to redirect its output and possibly input.","link":"/2020/08/01/An-Excursion-of-Linux-Job-and-Process-Management/"},{"title":"An Excursion of Linux: The Bash Shell","text":"Always double-check your arguments before executing a command. Common Bash Key Bindings Clear the screen. CTRL + L Delete a word from the left-hand side of the cursor CTRL + W Clear the line from the left-hand side of the cursor CTRL + U Erase from the cursor to end of line CTRL + K, K for kill the line Search through previously used commands in command history CTRL + R, press again for choosing a previous command. (R for recursive search) Perform the selected command CTRL + O Quit the search CTRL + G Kill the current process. CTRL + C Suspend the current process CTRL + Z; You can use fg to restore it. Delete the current character. CTRL + D Undo CTRL + _ Move the cursor to end of line. CTRL + E Move the cursor right/left CTRL + F/B, F/B for Forward/Back View the previous/next command CTRL + P/N Get erased text for the last time (for example, from CTRL-U) CTRL + Y Auto-complete arguments, commands, e.t.c. Tab CTRL+J the same as ENTER key. Open the current command in an editor for multi-line editing. First set the default editor: 12export VISUAL=vimexport EDITOR=&quot;$VISUAL&quot; CTRL + X + CTRL + E View the last command you run !! View the last command’s arguments ESC + . or !$ Exit the shell CTRL + D, i.e., it sends an EOF (End-of-file) marker to the bash. Environment Variable, Shell Variable and $PATHShell variables: temporary variables containing the values of text strings. Environment variables variables not specific to the shell. All processes on Unix systems have environment variable storage. The Command Path: $PATH PATH is a special environment variable that contains the command path (or path for short). A command path is a list of system directories that the shell searches when trying to locate a command. To tell the shell to look in more places: 1export PATH=&quot;$SOME_BIN_DIR:$PATH&quot; Shell ExpansionsFor reference, check out GNU Bash Manual Filename and Tilde ExpansionThe parent of a directory: .. The current directory: . The value of $HOME: ~ Brace expansionBrace expansion, PREAMBLLE{SEQUENCE}POSTSCRIPT, is a mechanism by which arbitrary strings may be generated. It is performed before any other expansions, and any characters special to other expansions are preserved in the result. The form of sequence expression is like {FOO..BAR..INCREMENT}, where FOO and BAR are either integers or single characters, and the optional INCREMENT, is an integer. By default, the range of the expression is inclusive and the increment is 1. To avoid conflicts with parameter expansion, the string ${ is considered not eligible for brace expansion. Examples: 123456789101112131415161718echo Preamble{A..H..2}{1..10..2}Postscript | tr &quot; &quot; &quot;\\n&quot;# Result:#PreambleA1Postscript#PreambleA3Postscript#PreambleA5Postscript#PreambleA7Postscript#PreambleA9Postscript#...#PreambleG9Postscriptecho TestFolder_{a..c}{1..10} | xargs mkdir# Take the result to create folders#drwxr-xr-x 32 foo ADSUSER 28672 Jul 1 08:35 ./#drwx------ 11 foo ADSUSER 4096 Jul 1 08:13 ../#drwxr-xr-x 2 foo ADSUSER 4096 Jul 1 08:35 TestFolder_a1/#...#drwxr-xr-x 2 foo ADSUSER 4096 Jul 1 08:35 TestFolder_c9/ Pattern MatchingRespectively, *, ?, [] matches any string, single character, a range. The sorting order of characters in range expressions is determined by the current locale and the values of the LC_COLLATE and LC_ALL shell variables, if set. What’s more, character classes can be specified using the syntax [:class-name:], where the class is one of the following classes defined in the POSIX standard: 12alnum alpha ascii blank cntrl digit graph lowerprint punct space upper word xdigit Extended Pattern MatchingTo check if extglob shell option is enabled, run shopt extglob. When it’s enabled, several extended pattern matching operators are recognized. In the following description, a pattern-list is a list of one or more patterns separated by a |. ?(pattern-list) : Matches zero or one occurrence of the given patterns.*(pattern-list) : Matches zero or more occurrences of the given patterns.+(pattern-list) : Matches one or more occurrences of the given patterns.@(pattern-list) : Matches one of the given patterns.!(pattern-list) : Matches anything except one of the given patterns. To improve the performance, using separate matches against shorter strings, or using arrays of strings instead of a single long string, maybe faster. Standard I/O and Pipesstdin code: 0 &lt;: use a file’s content as the standard input &lt;&lt;: means the end of input (like ctrl + D), which is known as the here-doc structure. Write multiple lines into a file: (The leading &gt; is automatically showed by bash) 1234cat &gt; some_file.txt &lt;&lt; EOF&gt; FOO&gt; BAR BAZ...&gt; EOF stdout code: 1 &gt;: To send the output of command to a file, use the &gt; redirection character. The shell creates file if it does not already exist. If file exists, the shell erases the original file first (overwrite). &gt;&gt;: like the &gt;, but you append the output to the file instead of overwriting it. stderr code: 2 Use 2&gt; or 2&gt;&gt; to write standard error into a file Examples: 12345678# Split the output and error message to different filessome-command args &gt; output.txt 2&gt; error.txt# Ditch error outputsome-command args 2&gt; /dev/null# Write both the output and error message into one filesome-command args &gt; out.txt 2&gt;&amp;1# orsome-command args &amp;&gt; out.txt Understanding Error Messages You must read the error message because Unix errors usually tell you exactly what went wrong. When troubleshooting errors, always address the first error.","link":"/2020/05/27/An-Excursion-of-Linux-The-Bash-Shell/"},{"title":"Helm in Use: Deploy MySQL Database","text":"Use Helm Chart to Deploy a MySQL Instance Deploy MySQL with HelmCreate Secret 12345678910apiVersion: v1kind: Secretmetadata: name: mysql-standalone-secrettype: kubernetes.io/basic-authstringData: username: adrian mysql-root-password: MyPassw0rd mysql-password: MyPassw0rd mysql-replication-password: MyPassw0rd Create PVC using the default storage class 1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: mysql-standalone-claimspec: accessModes: - ReadWriteOnce storageClassName: local-path resources: requests: storage: 10Gi After created, the Persistent Volume Claim would be in state pending cause it isn’t get mounted by MySQL. Run helm install 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@dev kube-yml]# helm install mysql-master bitnami/mysql -f my-mysql-standalone-values.ymlNAME: mysql-masterLAST DEPLOYED: Sat Jul 17 20:37:35 2021NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:** Please be patient while the chart is being deployed **Tip: Watch the deployment status using the command: kubectl get pods -w --namespace defaultServices: echo Primary: mysql-master.default.svc.cluster.local:3306Administrator credentials: echo Username: root echo Password : $(kubectl get secret --namespace default mysql-standalone-secret -o jsonpath=&quot;{.data.mysql-root-password}&quot; | base64 --decode)To connect to your database: 1. Run a pod that you can use as a client: kubectl run mysql-master-client --rm --tty -i --restart='Never' --image docker.io/bitnami/mysql:8.0.25-debian-10-r37 --namespace default --command -- bash 2. To connect to primary service (read/write): mysql -h mysql-master.default.svc.cluster.local -uroot -p my_databaseTo access the MySQL Prometheus metrics from outside the cluster execute the following commands: kubectl port-forward --namespace default svc/mysql-master-metrics 9104:9104 &amp; curl http://127.0.0.1:9104/metricsTo upgrade this helm chart: 1. Obtain the password as described on the 'Administrator credentials' section and set the 'root.password' parameter as shown below: ROOT_PASSWORD=$(kubectl get secret --namespace default mysql-master -o jsonpath=&quot;{.data.mysql-root-password}&quot; | base64 --decode) helm upgrade --namespace default mysql-master bitnami/mysql --set auth.rootPassword=$ROOT_PASSWORD Check if it works Connect it via Client Application Sakila Sample DatabaseThe docker image does not come with the sample database sakila. We can install it manually via the official SQL scripts. Return 100 random records in film table with id and title. SELECT film_id,title FROM film ORDER BY RAND() LIMIT 10; The result will be simliar to this: 1234567891011film_id title702 PULP BEVERLY940 VICTORY ACADEMY800 SINNERS ATLANTIS206 DANCING FEVER763 SATISFACTION CONFIDENTIAL989 WORKING MICROCOSMOS250 DRAGON SQUAD647 OUTFIELD MASSACRE414 HELLFIGHTERS SIERRA100 BROOKLYN DESERT","link":"/2021/07/28/Helm-in-Use-Deploy-MySQL-Database/"},{"title":"An Excursion of Linux: Documentation and Help","text":"Get some help. man — The System’s Manual PagerThe meaning of section number: 0: Header files (usually found in /usr/include) 1: Executable programs or shell commands 2: System calls (functions provided by the kernel) 3: Library calls (functions within program libraries) 4: Special files (usually found in /dev) 5: File formats and conventions eg /etc/passwd 6: Games 7: Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7) 8: System administration commands (usually only for root) 9: Kernel routines [Non standard] Bash Help: Run help or help -d Online ResourcesGNU: https://www.gnu.org/software/Online Man Page https://man.cx/Cheatsheet http://cheat.sh/ https://github.com/tldr-pages/tldr","link":"/2020/07/30/An-Excursion-of-Linux-Documentation-and-Help/"},{"title":"An Excursion of Linux: Dot Files at Home","text":"Put the right config in the right files. ~/.bash_profileIt loads .profile and .bashrc.It contains environment variables and commands that should be executed when you login in. 123# Include ~/.bashrcif [ -r ~/.profile ]; then . ~/.profile; ficase &quot;$-&quot; in *i*) if [ -r ~/.bashrc ]; then . ~/.bashrc; fi;; esac The Bash, when it is invoked as the login shell, reads commands from ~/.bash_profile, and if that file doesn’t exist, it tries reading ~/.profile instead. ~/.bash_profile can be used instead of ~/.profile and it’s Bash-only. /etc/profileThe default shell (bash for example) reads commands from it when it is invoked as the login shell (Noted that the terminal window from a GUI is not a login shell.). The profile contains global variables, alias and it should not be edited directly because there are chances that the changes may get overwrited during a system update. The comment in this file told us to use /etc/profile.local instead.Also, if there is anything related to GUI application, it must be in this file. ~/.bashrcThis file is used for putting configs that apply to the Bash itself only, such as alias, function definitions, shell options, and prompt settings.The non-login shell can use it as to set up your Bash environment. ~/.inputrcIt stores the settings that control the behavior of the readline library for the Bash. (e.g. key bindings).","link":"/2021/07/21/An-Excursion-of-Linux-Dot-Files-at-Home/"},{"title":"Helm in Use: Deploy Redis Cluster","text":"Use Helm Chart to Deploy a Redis Cluster (3 Masters + 3 Replica) Redis Clusterhttps://artifacthub.io/packages/helm/bitnami/redis-cluster https://github.com/bitnami/charts/tree/master/bitnami/redis-cluster https://rancher.com/blog/2019/deploying-redis-cluster 1234567891011121314151617181920212223242526272829[root@dev kube-yml]# cat &lt;&lt; EOF &gt; my-redis-cluster-values.yml&gt; global.storageClass: local-path&gt; global.redis.password: MyPassw0rd&gt; service.type: NodePort&gt; metrics.enabled: true&gt; EOF[root@dev kube-yml]# helm install --timeout 600s redis-cluster bitnami/redis-cluster -f my-redis-cluster-values.ymlNAME: redis-clusterLAST DEPLOYED: Sun Jul 18 21:15:37 2021NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:** Please be patient while the chart is being deployed **To get your password run: export REDIS_PASSWORD=$(kubectl get secret --namespace &quot;default&quot; redis-cluster -o jsonpath=&quot;{.data.redis-password}&quot; | base64 --decode)You have deployed a Redis(TM) Cluster accessible only from within you Kubernetes Cluster.INFO: The Job to create the cluster will be created.To connect to your Redis(TM) cluster:1. Run a Redis(TM) pod that you can use as a client:kubectl run --namespace default redis-cluster-client --rm --tty -i --restart='Never' \\ --env REDIS_PASSWORD=$REDIS_PASSWORD \\--image docker.io/bitnami/redis-cluster:6.2.4-debian-10-r21 -- bash2. Connect using the Redis(TM) CLI:redis-cli -c -h redis-cluster -a $REDIS_PASSWORD Change Service Type to LoadBalancer type: LoadBalancer Check 3 Main, 3 Replica 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061[root@dev kube-yml]# kubectl exec -it redis-cluster-0 -- redis-cli cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:6324cluster_stats_messages_pong_sent:6484cluster_stats_messages_sent:12808cluster_stats_messages_ping_received:6479cluster_stats_messages_pong_received:6324cluster_stats_messages_meet_received:5cluster_stats_messages_received:12808[root@dev kube-yml]# for x in $(seq 0 5); do echo &quot;redis-cluster-$x&quot;; kubectl exec redis-cluster-$x -- redis-cli role; echo; doneredis-cluster-0master884810.42.0.9063798848redis-cluster-1master884810.42.0.8963798848redis-cluster-2master884810.42.0.8863798848redis-cluster-3slave10.42.0.856379connected8848redis-cluster-4slave10.42.0.836379connected8848redis-cluster-5slave10.42.0.846379connected8848[root@dev kube-yml]# Install client brew install redis Connect to the cluster 12192.168.50.64:31169&gt; AUTH PASSWORDOK","link":"/2021/07/28/Helm-in-Use-Deploy-Redis-Cluser/"},{"title":"Hexo Up and Running, a Github Page Hosted Way","text":"Deploy and host the static website on Github Page, using Cloudflare to resolve CNAME. Edit Hexo ConfigurationSite URL12## Set your site url here. For example, if you use GitHub Page, set url as 'https://username.github.io/project'url: https://dumb-tiger.github.io/ Deploy1234deploy: type: git repo: https://github.com/Dumb-Tiger/dumb-tiger.github.io.git branch: gh-pages CNAME File at themes/$THEME/source/CNAME1blog.tigersfactory.com Build and DeployRun the following command in the project root folder (i.e., where your _config.yml located) to install the deployer. npm install hexo-deployer-git --save Noted that if the token or SSH key is not set before, an authentication using Github username and password is needed. 1hexo clean &amp;&amp; hexo deploy Configure the Github Page Repository Go to Settings -&gt; Pages Add the hostname at Custom domain and click Save. Add a CNAME Record at CloudflareHere I assign my sub domain blog.tigersfactory.com to the Github Page. Wait some minutes and clean up the local cache if you’ve visited the site before. ReferenceOne Command Deployment by Git About custom domains and GitHub Pages","link":"/2021/06/30/Hexo-Up-and-Running-a-Github-Page-Hosted-Way/"},{"title":"Self-hosted K8s: Setting Up","text":"This post describes how to set up a self-hosted K8s cluster from scratch, by just using an old computer at home. EnvironmentServer(PC) Spec. >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374[root@dev ~]# lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 8On-line CPU(s) list: 0-7Thread(s) per core: 2Core(s) per socket: 4Socket(s): 1NUMA node(s): 1Vendor ID: GenuineIntelCPU family: 6Model: 94Model name: Intel(R) Core(TM) i7-6770HQ CPU @ 2.60GHzStepping: 3CPU MHz: 833.129CPU max MHz: 3500.0000CPU min MHz: 800.0000BogoMIPS: 5184.00Virtualization: VT-xL1d cache: 32KL1i cache: 32KL2 cache: 256KL3 cache: 6144KNUMA node0 CPU(s): 0-7Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear spec_ctrl intel_stibp flush_l1d[root@dev ~]# cat /proc/meminfoMemTotal: 16317680 kBMemFree: 14494044 kBMemAvailable: 14841560 kBBuffers: 2120 kBCached: 600708 kBSwapCached: 0 kBActive: 1002416 kBInactive: 498124 kBActive(anon): 898416 kBInactive(anon): 10536 kBActive(file): 104000 kBInactive(file): 487588 kBUnevictable: 0 kBMlocked: 0 kBSwapTotal: 0 kBSwapFree: 0 kBDirty: 1048 kBWriteback: 0 kBAnonPages: 897840 kBMapped: 209356 kBShmem: 11240 kBSlab: 75176 kBSReclaimable: 35656 kBSUnreclaim: 39520 kBKernelStack: 11216 kBPageTables: 9608 kBNFS_Unstable: 0 kBBounce: 0 kBWritebackTmp: 0 kBCommitLimit: 8158840 kBCommitted_AS: 5102612 kBVmallocTotal: 34359738367 kBVmallocUsed: 576216 kBVmallocChunk: 34358423548 kBPercpu: 3232 kBHardwareCorrupted: 0 kBAnonHugePages: 618496 kBCmaTotal: 0 kBCmaFree: 0 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBDirectMap4k: 97744 kBDirectMap2M: 3983360 kBDirectMap1G: 12582912 kB PrerequisiteDisable Firewallsystemctl stop firewalldsystemctl disable firewalld Disable SELINUXsed -i 's/enforcing/disabled/' /etc/selinux/config Disable swapFirst swapoff -a to temporarily turn off swap, then comment out the swap partition in /etc/fstab to disable it permanently. #/dev/mapper/centos-swap swap swap defaults 0 0 Set up hostname1234567891011[root@dev ~]# hostnamectl set-hostname dev.local[root@dev ~]# hostnamectl status Static hostname: dev.local Icon name: computer-desktop Chassis: desktop Machine ID: db95018bfd674a19ab4877b4c18add20 Boot ID: 420cdaba8c694200afcd1b1a0fa34178 Operating System: CentOS Linux 7 (Core) CPE OS Name: cpe:/o:centos:centos:7 Kernel: Linux 3.10.0-1160.31.1.el7.x86_64 Architecture: x86-64 Edit local hosts fileJust because I don’t want to set up bind for just several local domain name. If you have other nodes, don’t forget to add the hostnames in the master node’s hosts file. 12345vim /etc/hosts192.168.50.64 k8s-dashboard.dev.local192.168.50.64 dev.local... NTP UpdateActually I update the ntp during the OS installation. ntpdate time.windows.com Misc.These configuration may not concern the deployment of K3s, but I’ll do it anyway for a newly installed server. Install docker-ce, docker-ce-cli and containerd.ioAs I would like to use docker on this server, so I install it personally. Install the yum-utils package, which provides the yum-config-manager utility, and set up the stable repository. 12345sudo yum install -y yum-utilssudo yum-config-manager \\ --add-repo \\ &lt;https://download.docker.com/linux/centos/docker-ce.repo&gt;\\sudo yum install docker-ce docker-ce-cli containerd.io Start docker and check if it works. 1234567891011121314151617181920212223242526272829[root@dev-server ~]# systemctl start docker[root@dev-server ~]# systemctl enable docker[root@dev-server ~]# docker run hello-worldUnable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-worldb8dfde127a29: Pull completeDigest: sha256:9f6ad537c5132bcce57f7a0a20e317228d382c3cd61edae14650eec68b2b345cStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: &lt;https://hub.docker.com/&gt;For more examples and ideas, visit: &lt;https://docs.docker.com/get-started/&gt; Disable ipv6 1234567sysctl -pnet.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1vi /etc/ssh/sshd_config....AddressFamily inet Add name servers to evade from Gov(CN) DNS pollution 1234[root@dev ~]# nmcli connection showNAME UUID TYPE DEVICEeno1 3e5fb656-a48e-4902-8ea8-86a9d8e0cdc6 ethernet eno1[root@localhost etc]# nmcli connection modify eno1 ipv4.dns &quot;1.1.1.1 119.29.29.29&quot; Setting Up K3sK3s by default uses Traefik as the Ingress Controller. As I prefer to use Nginx instead, thus adding the following variable to exclude traefik installation. curl -sfL [https://get.k3s.io](https://get.k3s.io/) | INSTALL_K3S_EXEC=&quot;--disable traefik&quot; sh As mentioned in the K3s doc, we have to export KUBECONFIG to enable command line tools like kubectl and helm to work properly. Add the following to ~/.bashrc export KUBECONFIG=/etc/rancher/k3s/k3s.yaml Install HelmTo install Helm, just download the binary file then put it under the /usr/local/bin with proper permission. Add and Update Helm Repository12345678910111213# helm repo add stable https://charts.helm.sh/stable&quot;stable&quot; has been added to your repositories# helm repo add bitnami https://charts.bitnami.com/bitnami&quot;bitnami&quot; has been added to your repositories# helm repo listNAME URLstable https://charts.helm.sh/stablebitnami https://charts.bitnami.com/bitnami# helm repo updateHang tight while we grab the latest from your chart repositories......Successfully got an update from the &quot;bitnami&quot; chart repository...Successfully got an update from the &quot;stable&quot; chart repositoryUpdate Complete. ⎈Happy Helming!⎈ Install nginx-ingress-controller by Helm ChartFirst I dump the configurable values into a local file for further customizing. helm show values ingress-nginx/ingress-nginx &gt; values.yml Then I pick up some attributes to make a tiny values.yml. 123456789101112## Required on CNI based K8s installations, since CNI and hostport don't mix yet.hostNetwork: true## Optionally, change this to ClusterFirstWithHostNet in case you have 'hostNetwork: true'.## By default, while using host network, name resolution uses the host's DNS. If you wish nginx-controller## to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.dnsPolicy: ClusterFirstWithHostNet## Service parameters## Use NodePort to expose services to my client machine.service: type: NodePort After the installation, you will see results like this. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657NAME: nginx-ingress-controllerLAST DEPLOYED: Thu Jul 8 01:30:46 2021NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:** Please be patient while the chart is being deployed **The nginx-ingress controller has been installed.Get the application URL by running these commands: export HTTP_NODE_PORT=$(kubectl --namespace default get services -o jsonpath=&quot;{.spec.ports[0].nodePort}&quot; nginx-ingress-controller) export HTTPS_NODE_PORT=$(kubectl --namespace default get services -o jsonpath=&quot;{.spec.ports[1].nodePort}&quot; nginx-ingress-controller) export NODE_IP=$(kubectl --namespace default get nodes -o jsonpath=&quot;{.items[0].status.addresses[1].address}&quot;) echo &quot;Visit http://$NODE_IP:$HTTP_NODE_PORT to access your application via HTTP.&quot; echo &quot;Visit https://$NODE_IP:$HTTPS_NODE_PORT to access your application via HTTPS.&quot;An example Ingress that makes use of the controller: apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: example namespace: foo spec: rules: - host: www.example.com http: paths: - backend: service: name: exampleService port: number: 80 path: / pathType: Prefix # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tlsIf TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: &lt;base64 encoded cert&gt; tls.key: &lt;base64 encoded key&gt; type: kubernetes.io/tls Bash Completion for Command Line ToolsAuto-completion makes your life easier. 123yum install bash-completionkubectl completion bash &gt;/etc/bash_completion.d/kubectlhelm completion bash &gt; /etc/bash_completion.d/helm Deploy Kubernetes DashboardPrerequisite for HTTPsTo visit our dashboard via HTTPS, we need to specify a TLS secret in our values.yml. Kubernetes Secret # tls-secrets Kubernetes provides a builtin Secret type kubernetes.io/tls for storing a certificate and its associated key that are typically used for TLS . This data is primarily used with TLS termination of the Ingress resource, but may be used with other resources or directly by a workload. When using this type of Secret, the tls.key and the tls.crt key must be provided in the data (or stringData) field of the Secret configuration, although the API server doesn’t actually validate the values for each key. To create it, we first generate a self-signed certification by using openssl. 1234openssl req -newkey rsa:2048 \\-nodes -keyout k8s-dashboard-dev-local-key.pem -x509 \\-days 3650 -out k8s-dashboard-dev-local-certificate.pem \\-subj &quot;/CN=k8s-dashboard.dev.local&quot; You’ll see the key and cert files in the current directory. 123456[root@dev secrets]# ltotal 20drwxr-xr-x 2 root root 150 Jul 10 22:50 .dr-xr-x---. 12 root root 4096 Jul 10 22:31 ..-rw-r--r-- 1 root root 1131 Jul 10 22:50 k8s-dashboard-dev-local-certificate.pem-rw-r--r-- 1 root root 1704 Jul 10 22:50 k8s-dashboard-dev-local-key.pem Then we use them to create the secret. When creating a TLS Secret using kubectl, you can use the tls subcommand as shown in the following example: 123kubectl create secret tls my-tls-secret\\ --cert=path/to/cert/file\\ --key=path/to/key/file Create Service Account and Role Binding12345678910111213141516171819202122232425[root@dev ~]# cat &lt;&lt; EOF | kubectl apply -f -&gt; apiVersion: v1&gt; kind: ServiceAccount&gt; metadata:&gt; name: admin-user&gt; namespace: default&gt; ---&gt; apiVersion: rbac.authorization.k8s.io/v1&gt; kind: ClusterRoleBinding&gt; metadata:&gt; name: admin-user&gt; roleRef:&gt; apiGroup: rbac.authorization.k8s.io&gt; kind: ClusterRole&gt; name: cluster-admin&gt; subjects:&gt; - kind: ServiceAccount&gt; name: admin-user&gt; namespace: default&gt; EOFserviceaccount/admin-user createdclusterrolebinding.rbac.authorization.k8s.io/admin-user created[root@dev ~]# kubectl -n default get secret $(kubectl -n default get sa/admin-user -o jsonpath=&quot;{.secrets[0].name}&quot;) -o go-template=&quot;{{.data.token | base64decode}}&quot;# The Secret Goes Here... Prepare values.yml and Install the Helm Chart123456789101112131415[root@dev kube-yml]# cat &lt;&lt; EOF &gt; values.yml&gt; service:&gt; type: NodePort&gt; externalPort: 443&gt; ingress:&gt; enabled: true&gt; hosts:&gt; - k8s-dashboard.dev.local&gt; annotations:&gt; nginx.ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;&gt; tls:&gt; - secretName: k8s-dashboard-local-dev-secret&gt; hosts:&gt; - k8s-dashboard.dev.local&gt; EOF helm install -f ~/kube-yml/values.yml kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard You will see output like this: 123456789101112NAME: kubernetes-dashboardLAST DEPLOYED: Sat Jul 10 22:16:29 2021NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:************************************************************************************ PLEASE BE PATIENT: kubernetes-dashboard may take a few minutes to install ************************************************************************************From outside the cluster, the server URL(s) are: https://k8s-dashboard.dev.local Check the Dashboard","link":"/2021/07/11/Self-hosted-K8s-Setting-Up/"},{"title":"Learning to Learn","text":"Feynman Technique -&gt; Learn by Teaching OthersLearning From the Feynman Technique | by Evernote | Taking Note | Medium The Feynman Technique: The Best Way to Learn Anything (fs.blog) How to Use the Feynman Technique to Learn Faster (With Examples) (collegeinfogeek.com) Active Recall -&gt; Test Yourself !Active Recall Misc.Use Scrum / Agile (retrospective) to manage your learning project. Make your own problem set for review. Use mind map to explain a concept. Before you start reading a text book, test yourself by checking the indices of the book. Investigate the error distribution and its frequency. Have a sense of ceremony.","link":"/2020/06/28/Learning-to-Learn/"},{"title":"Wall Crossing: A Simple Guide to Shadowsocks and V2Ray","text":"This passage introduces how to configure and use network proxy like Shadowsocks and V2Ray without GUI. ShadowsocksBuild from Source123456789101112131415161718192021222324252627git clone https://github.com/shadowsocks/shadowsocks-libev.gitgit submodule init &amp;&amp; git submodule updateyum install gcc gettext autoconf libtool automake make pcre-devel asciidoc xmlto c-ares-devel libev-devel libsodium-devel mbedtls-devel -y# Installation of libsodiumexport LIBSODIUM_VER=1.0.16wget https://download.libsodium.org/libsodium/releases/old/libsodium-$LIBSODIUM_VER.tar.gztar xvf libsodium-$LIBSODIUM_VER.tar.gzpushd libsodium-$LIBSODIUM_VER./configure --prefix=/usr &amp;&amp; makesudo make installpopdsudo ldconfig# Installation of MbedTLSexport MBEDTLS_VER=2.6.0wget https://tls.mbed.org/download/mbedtls-$MBEDTLS_VER-gpl.tgztar xvf mbedtls-$MBEDTLS_VER-gpl.tgzpushd mbedtls-$MBEDTLS_VERmake SHARED=1 CFLAGS=&quot;-O2 -fPIC&quot;sudo make DESTDIR=/usr installpopdsudo ldconfig# Start building./autogen.sh &amp;&amp; ./configure &amp;&amp; makesudo make install Configure shadowsocks-libev Create Custom Configs under /etc/shadowsocks/custom-config.d Example 123456789{ &quot;server_port&quot; : 0000, &quot;server&quot; : &quot;example.com&quot;, &quot;local_port&quot; : 0000, &quot;timeout&quot; : 60, &quot;method&quot; : &quot;aes-256-gcm&quot;, &quot;password&quot; : &quot;FOOBARBAZ&quot;, &quot;local_address&quot; : &quot;127.0.0.1&quot;} Locate the service of client service 123456adrian-pc:/etc/systemd/system # systemctl status shadowsocks-libev-client.service● shadowsocks-libev-client.service - Daemon to start Shadowsocks-libev-client Loaded: loaded (/usr/lib/systemd/system/shadowsocks-libev-client.service; disabled; vendor preset: disabled) Active: inactive (dead)Jun 06 17:50:46 adrian-pc systemd[1]: /usr/lib/systemd/system/shadowsocks-libev-client.service:8: PIDFile= references a path below legacy directory /var/run/, updating /var/run/shadowsocks-libev-client.pid → /run/shadowsocks-libev&gt; Make a backup 1rsync -az /usr/lib/systemd/system/shadowsocks-libev-client.service ~/shadowsocks-libev-client.service.bak Start and check status 123456789101112131415161718adrian-pc:/usr/lib/systemd/system # systemctl start shadowsocks-libev-client.serviceadrian-pc:/usr/lib/systemd/system # systemctl status shadowsocks-libev-client.service● shadowsocks-libev-client.service - Daemon to start Shadowsocks-libev-client Loaded: loaded (/usr/lib/systemd/system/shadowsocks-libev-client.service; disabled; vendor preset: disabled) Active: active (running) since Sun 2021-06-06 18:04:10 CST; 10s ago Process: 14286 ExecStart=/usr/bin/ss-local -c /etc/shadowsocks/just_my_socks.d/s1.json -f /var/run/shadowsocks-libev-client.pid -u --fast-open (code=exited, status=0/SUCCESS) Main PID: 14287 (ss-local) Tasks: 1 (limit: 4915) CGroup: /system.slice/shadowsocks-libev-client.service └─14287 /usr/bin/ss-local -c /etc/shadowsocks/just_my_socks.d/s1.json -f /var/run/shadowsocks-libev-client.pid -u --fast-openJun 06 18:04:10 adrian-pc systemd[1]: Starting Daemon to start Shadowsocks-libev-client...Jun 06 18:04:10 adrian-pc /usr/bin/ss-local[14287]: using tcp fast openJun 06 18:04:10 adrian-pc systemd[1]: Started Daemon to start Shadowsocks-libev-client.Jun 06 18:04:10 adrian-pc /usr/bin/ss-local[14287]: initializing ciphers... aes-256-gcmJun 06 18:04:10 adrian-pc /usr/bin/ss-local[14287]: listening at 127.0.0.1:1086Jun 06 18:04:10 adrian-pc /usr/bin/ss-local[14287]: udprelay enabledJun 06 18:04:10 adrian-pc /usr/bin/ss-local[14287]: running from root user V2RayInstallationFor script users, make sure your DNS resolution is working fine because some China ISP hijack the https://raw.githubusercontent.com/. Personally, I prefer the pre-compiled package, which looks like this after decompressed. 123456789101112v2ray-linux-64├── config.json├── geoip.dat├── geosite.dat├── systemd│ └── system│ ├── v2ray.service│ └── v2ray@.service├── v2ctl├── v2ray├── vpoint_socks_vmess.json└── vpoint_vmess_freedom.json Copy these files to the following location. 12345/usr/bin/v2ray/v2ray: V2Ray executable/usr/bin/v2ray/v2ctl: Utility/etc/v2ray/config.json: Config file/usr/bin/v2ray/geoip.dat: IP data file/usr/bin/v2ray/geosite.dat: domain data file As I use Manjaro in my daily working, so I just use the one from https://archlinux.org/packages/community/x86_64/v2ray/. ConfigurationHere is a systemd service file I used for the v2ray. It will perform a pre-check for the configuration json and runs only after the nss-lookup is working because I have a domain name for the proxy server. Also please replace the MY_V2RAY_CONFIG.json with your configuration file name. 1234567891011121314151617[Unit]Description=The V2Ray Client ServiceDocumentation=https://www.v2fly.org/After=network.target nss-lookup.target[Service]Type=simpleCapabilityBoundingSet=CAP_NET_ADMIN CAP_NET_BIND_SERVICEAmbientCapabilities=CAP_NET_ADMIN CAP_NET_BIND_SERVICENoNewPrivileges=trueExecStartPre=/usr/bin/v2ray -c /etc/v2ray/MY_V2RAY_CONFIG.json -testExecStart=/usr/bin/v2ray -c /etc/v2ray/MY_V2RAY_CONFIG.jsonRestart=on-failureRestartPreventExitStatus=23[Install]WantedBy=multi-user.target proxychainsInstall12345678# needs a working C compiler, preferably gcc./configure --prefix=/usr --sysconfdir=/etcmake[optional] sudo make install[optional] sudo make install-config (installs proxychains.conf)if you dont install, you can use proxychains from the build directorylike this: ./proxychains4 -f src/proxychains.conf telnet google.com 80 Configuration123456789adrian-pc:/usr/lib/systemd/system # rsync -az /etc/proxychains.conf ~/proxychains.conf.bakadrian-pc:/usr/lib/systemd/system # vim /etc/proxychains.conf...[ProxyList]# add proxy here ...# meanwile# defaults set to &quot;tor&quot;#socks4 127.0.0.1 9050 socks5 127.0.0.1 1086","link":"/2021/10/30/Wall-Crossing-A-Simple-Guide-to-Shadowsocks-and-V2Ray/"},{"title":"Prometheous, Up and Running","text":"Deploy Prometheous to monitor node performance, cluster, application and more… Prometheouscreate tls 123openssl req -newkey rsa:2048 -nodes -keyout prometheus-dev-local-key.pem -x509 -days 3650 -out prometheus-dev-local-certificate.pem -subj &quot;/CN=prometheus.dev.local&quot;kubectl create secret tls prometheus-local-dev-secret --cert=./prometheus-dev-local-certificate.pem --key=./prometheus-dev-local-key.pem Install 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@dev kube-yml]# cat &lt;&lt; EOF &gt; prometheus-values.yml&gt; server:&gt; ingress:&gt; enabled: true&gt; hosts:&gt; - prometheus.dev.local&gt; tls:&gt; - secretName: prometheus-local-dev-secret&gt; hosts:&gt; - prometheus.dev.local&gt; EOF[root@dev kube-yml]# helm install prometheus prometheus-community/prometheus -f prometheus-values.ymlNAME: prometheusLAST DEPLOYED: Sat Jul 17 22:56:09 2021NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:The Prometheus server can be accessed via port 80 on the following DNS name from within your cluster:prometheus-server.default.svc.cluster.localFrom outside the cluster, the server URL(s) are:http://prometheus.dev.localThe Prometheus alertmanager can be accessed via port 80 on the following DNS name from within your cluster:prometheus-alertmanager.default.svc.cluster.localGet the Alertmanager URL by running these commands in the same shell: export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=prometheus,component=alertmanager&quot; -o jsonpath=&quot;{.items[0].metadata.name}&quot;) kubectl --namespace default port-forward $POD_NAME 9093####################################################################################### WARNING: Pod Security Policy has been moved to a global property. ########### use .Values.podSecurityPolicy.enabled with pod-based ########### annotations ########### (e.g. .Values.nodeExporter.podSecurityPolicy.annotations) ######################################################################################The Prometheus PushGateway can be accessed via port 9091 on the following DNS name from within your cluster:prometheus-pushgateway.default.svc.cluster.localGet the PushGateway URL by running these commands in the same shell: export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=prometheus,component=pushgateway&quot; -o jsonpath=&quot;{.items[0].metadata.name}&quot;) kubectl --namespace default port-forward $POD_NAME 9091For more information on running Prometheus, visit:https://prometheus.io/ ImagePullBackOff 1234567891011[root@dev kube-yml]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx-ingress-controller-default-backend-7645cbb448-lqsn8 1/1 Running 7 9dkubernetes-dashboard-5bc499658-2kwcl 1/1 Running 5 7dnginx-ingress-controller-dc849f5d5-m4bdt 1/1 Running 7 9dmysql-master-0 2/2 Running 0 151mprometheus-node-exporter-k6sp9 1/1 Running 0 13mprometheus-pushgateway-7646948557-m6pmr 1/1 Running 0 13mprometheus-alertmanager-84d9fdb9b8-7487n 2/2 Running 0 13mprometheus-server-7878c5bc6-c9v5q 2/2 Running 0 13mprometheus-kube-state-metrics-bc6c8c864-j8wrk 0/1 ImagePullBackOff 0 13m 12345678910Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 13m default-scheduler Successfully assigned default/prometheus-kube-state-metrics-bc6c8c864-j8wrk to dev.local Warning Failed 13m kubelet Failed to pull image &quot;k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0&quot;: rpc error: code = Unknown desc = failed to pull and unpack image &quot;k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0&quot;: failed to resolve reference &quot;k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0&quot;: failed to do request: Head &quot;https://k8s.gcr.io/v2/kube-state-metrics/kube-state-metrics/manifests/v2.0.0&quot;: dial tcp 64.233.189.82:443: i/o timeout Normal Pulling 10m (x4 over 13m) kubelet Pulling image &quot;k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0&quot; Warning Failed 10m (x4 over 13m) kubelet Error: ErrImagePull Warning Failed 9m51s (x6 over 13m) kubelet Error: ImagePullBackOff Warning Failed 8m6s (x4 over 12m) kubelet Failed to pull image &quot;k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0&quot;: rpc error: code = Unknown desc = failed to pull and unpack image &quot;k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0&quot;: failed to resolve reference &quot;k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0&quot;: failed to do request: Head &quot;https://k8s.gcr.io/v2/kube-state-metrics/kube-state-metrics/manifests/v2.0.0&quot;: dial tcp 108.177.97.82:443: i/o timeout Normal BackOff 3m26s (x29 over 13m) kubelet Back-off pulling image &quot;k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0&quot; 1234567891011121314151617181920212223242526[root@dev kube-yml]# ping k8s.gcr.ioPING googlecode.l.googleusercontent.com (74.125.203.82) 56(84) bytes of data.^C--- googlecode.l.googleusercontent.com ping statistics ---10 packets transmitted, 0 received, 100% packet loss, time 8999ms[root@dev kube-yml]# dig k8s.gcr.io; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7_9.5 &lt;&lt;&gt;&gt; k8s.gcr.io;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 10778;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;k8s.gcr.io. IN A;; ANSWER SECTION:k8s.gcr.io. 64700 IN CNAME googlecode.l.googleusercontent.com.googlecode.l.googleusercontent.com. 511 IN A 74.125.203.82;; Query time: 0 msec;; SERVER: 192.168.50.1#53(192.168.50.1);; WHEN: Sat Jul 17 23:11:34 CST 2021;; MSG SIZE rcvd: 103 123456789101112[root@dev kube-yml]# docker pull k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)[root@dev kube-yml]# docker pull bitnami/kube-state-metrics:22: Pulling from bitnami/kube-state-metrics76bfd0e40570: Pull complete19a8a9360f70: Pull complete56a71ce31d74: Pull completec95de4ccfbd0: Pull complete692ee571958b: Pull completeDigest: sha256:2a3da8d5722834b36c6080c3d976e01ee764f2f3c4e6f3f03e92d6a2d6fb58a5Status: Downloaded newer image for bitnami/kube-state-metrics:2docker.io/bitnami/kube-state-metrics:2 Edit ReplicaSet &amp; Deployment, update the image to another repository. 1234spec: containers: - name: kube-state-metrics **image: bitnami/kube-state-metrics:2.0.0** Test if it works 1234helm repo add grafana https://grafana.github.io/helm-chartshelm repo updateopenssl req -newkey rsa:2048 -nodes -keyout grafana-dev-local-key.pem -x509 -days 3650 -out grafana-dev-local-certificate.pem -subj &quot;/CN=grafana.dev.local&quot;kubectl create secret tls grafana-local-dev-tls --cert=./grafana-dev-local-certificate.pem --key=./grafana-dev-local-key.pem 1[root@dev kube-yml]# helm install -f my-grafana-values.yml grafana grafana/grafanaW0718 01:50:27.314145 10226 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+W0718 01:50:27.316070 10226 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+W0718 01:50:27.360206 10226 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+W0718 01:50:27.361112 10226 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+NAME: grafanaLAST DEPLOYED: Sun Jul 18 01:50:26 2021NAMESPACE: defaultSTATUS: deployedREVISION: 1NOTES:1. Get your 'admin' user password by running: kubectl get secret --namespace default grafana -o jsonpath=&quot;{.data.admin-password}&quot; | base64 --decode ; echo2. The Grafana server can be accessed via port 80 on the following DNS name from within your cluster: grafana.default.svc.cluster.local If you bind grafana to 80, please update values in values.yaml and reinstall: securityContext: runAsUser: 0 runAsGroup: 0 fsGroup: 0 command: “setcap” “‘cap_net_bind_service=+ep’” “/usr/sbin/grafana-server &amp;&amp;” “sh” “/run.sh” 1Details refer to https://grafana.com/docs/installation/configuration/#http-port. Or grafana would always crash. From outside the cluster, the server URL(s) are: http://grafana.dev.local3. Login with the password from step 1 and the username: admin[root@dev kube-yml]# kubectl get secret --namespace default grafana -o jsonpath=&quot;{.data.admin-password}&quot; | base64 --decode ; echoRN2EPFI7MJPSLZamEp2g3jzwEyZcHXHWTZAsFaax","link":"/2021/07/28/Prometheous-Up-and-Running/"},{"title":"A Big Picture of Linux","text":"The main components of Linux and operation basics, I’m going to remove this post after sub-posts are done. Main Components User Processes: GUI, Servers, Shell, etc. Linux Kernel: System Calls, Process Management, Memory Management, Device Drivers Hardware: Processor (CPU), Main Memory (RAM), Disks, Network Ports Process Management: starting, pausing, resuming, and terminating A job of memory management by the kernel: The kernel must have its own private area in memory that user processes can’t access. Each user process needs its own section of memory. One user process may not access the private memory of others. User processes can share memory. Some memory in user processes can be read-only. The system can use more memory than is physically present by using disk space as auxiliary (swap). Modern CPUs include a memory management unit (MMU) that enables a memory access scheme called virtual memory. What does MMU do when the process accesses the memory? The MMU intercepts the access and uses a memory address map to translate the memory location from the process into an actual physical memory location on the machine. The kernel must still initialize and continuously maintain and alter this memory address map. The implementation of a memory address map is called a page table. Two important system calls about how processes start up fork() When a process calls fork(), the kernel creates a nearly identical copy of the process. exec() When a process calls exec(), the kernel starts the program, replacing the current process. The general procedure of starting a new process 12shell -&gt; fork() -&gt; shell -&gt; copy of shell -&gt; exec() -&gt; program User and Groups A user is an entity that can run processes and own files and it is associated with a username. Users exist primarily to support permissions and boundaries. Groups are sets of users. Noted that even the root user does not run in kernel mode. ps : report a snapshot of the current processes.Commonly, we use ps in BSD style and with grep to narrow down the result. Options: ax: list all processes. u: show detailed information with columns USER, PID, CPU, MEM, VSZ, RSS, TTY, STAT, START, TIME, COMMAND w: width output, use twice for unlimited width. Process State Code (From man ps) D: uninterruptible sleep (usually IO) R: running or runnable (on run queue) S: interruptible sleep (waiting for an event to complete) T: stopped, either by a job control signal or because it is being traced W: paging (not valid since the 2.6.xx kernel) X: dead (should never be seen) Z: defunct (“zombie”) process, terminated but not reaped by its parent For BSD formats and when the stat keyword is used, additional characters may be displayed: &lt;: high-priority (not nice to other users) N: low-priority (nice to other users) L: has pages locked into memory (for real-time and custom IO) s: is a session leader l: is multi-threaded (using CLONE_THREAD, like NPTL pthreads do) +: is in the foreground process group Examples: ps aux: list every process ps auxww: the same as above, but including the full command string. ps axjf: show process tree ps aux | grep '[s]ome-program': to exclude the grep process for this filtering. kill : send a signal to a processTo terminate a process, send it a signal with the kill command. The default is TERM, or terminate: kill PID To freeze a process instead of terminating it, use the STOP signal: kill -STOP PID Use the CONT signal to continue running the process again: kill -CONT PID Terminates the process and forcibly removes it from memory: kill -KILL PID Job ControlCTRL + Z: send a TSTP signal, which is similar to STOP. fg JOB_ID: bring the job to foreground. bg JOB_ID: let the job run in the background. jobs: Display status of jobs in the current session. Show status and process IDs of all jobs: jobs -l command &amp;: detach a process from the shell and put it in the “background.” The process will continue to run after you log out. If a program tries to read something from the standard input when it’s in the background, it can freeze (try fg to bring it back) or terminate. Make sure that a background process doesn’t bother you is to redirect its output and possibly input. File Modes and PermissionsFormat: FILE_TYPE|USER|GROUP|OTHER s in the user permissions indicates that the executable is setuid, meaning that when you execute the program, it runs as though the file owner is the user instead of you. Don’t forget the -s option when creating a symbolic link. Hard links point directly to the file data. Devices, Filesystem and DisksNowadays, I’ll skip this part because we really don’t touch those stuff in the cloud native era. How the Linux Kernel BootsA simplified view of the boot process: The machine’s BIOS or boot firmware loads and runs a boot loader. The boot loader finds the kernel image on disk, loads it into memory, and starts it. The kernel initializes the devices and its drivers. The kernel mounts the root filesystem. The kernel starts a program called init with a process ID of 1. This point is the user space start. init sets the rest of the system processes in motion. At some point, init starts a process allowing you to log in, usually at the end or near the end of the boot. Startup MessagesTo view the kernel’s boot and runtime diagnostic messages: Check /var/log/kernel, /var/log/messages or elsewhere. Use the dmesg command Kernel Initialization and Boot OptionsLinux kernel initializes in this general order: CPU inspection Memory inspection Device bus discovery Device discovery Auxiliary kernel subsystem setup (networking, and so on) Root filesystem mount User space start Kernel ParametersView the kernel parameters from your system’s boot by looking at the /proc/cmdline file: The parameters are either simple one-word flags or key=value pairs. The root parameter is the location of the root filesystem. (On most modern desktop systems, a UUID is more common than a device file.) Upon encountering a parameter that it does not understand, the Linux kernel saves the parameter. The kernel later passes the parameter to init when performing the user space start. Boot LoadersBoot loaders use the Basic Input/Output System (BIOS) or Unified Extensible Firmware Interface (UEFI) to access disks. Nearly all disk hardware has firmware that allows the BIOS to access attached storage hardware with Linear Block Addressing (LBA). Boot loaders are often the only programs to use the BIOS for disk access; the kernel uses its own high-performance drivers. Boot Loader Tasks A Linux boot loader’s core functionality includes the ability to do the following: Select among multiple kernels. Switch between sets of kernel parameters. Allow the user to manually override and edit kernel image names and parameters (for example, to enter single-user mode). Provide support for booting other operating systems. How User Space StartsUser space starts in roughly this order: init Essential low-level services such as udevd and syslogd Network configuration Mid- and high-level services (cron, printing, and so on) Login prompts, GUIs, and other high-level applications Introduction to initThe init program is a user-space program located in /sbin. Major implementations of init in Linux distributions: System V init. A traditional sequenced init (Sys V, usually pronounced “sys-five”). Red Hat Enterprise Linux and several other distributions use this version. systemd. A software suite that provides an array of system components for Linux operating systems. The traditional init system is script-centric. systemd offers individual service daemons from the beginning some level of on-demand services (start some services only when needed). backward compatibility System V Runlevels runlevel is denoted by a number from 0 through 6. Check your system’s runlevel with the who -r command. systemdOne of its most significant features is its ability to defer the start of services and operating system features until they are necessary. What happens when systemd runs at boot time: systemd loads its configuration. systemd determines its boot goal, which is usually named default.target. systemd determines all of the dependencies of the default boot goal, dependencies of these dependencies, and so on. systemd activates the dependencies and the boot goal. After boot, systemd can react to system events (such as uevents) and activate additional components. Units and Unit Types Each type of capability is called a unit type, and each specific capability is called a unit. When you turn on a unit, you activate it. See systemd(1) manual page for all unit types. The boot-time tasks required in any Unix system: Service units. Control the traditional service daemons on a Unix system. Mount units. Control the attachment of filesystems to the system. Target units. Control other units, usually by grouping them. You can create a unit dependency tree diagram with the systemctl dot command. systemd Dependencies Unix boot-time tasks are fairly fault tolerant and can often fail without causing serious problems for standard services. Basic dependency types and styles: Requires Strict dependencies. When activating a unit with a Requires dependency unit, systemd attempts to activate the dependency unit. If the dependency unit fails, systemd deactivates the dependent unit. Wants. Dependencies for activation only. Upon activating a unit, systemd activates the unit’s Wants dependencies, but it doesn’t care if those dependencies fail. It does not propagate failures to other units. This is the way you should specify dependencies if possible. Requisite. Units that must already be active. Before activating a unit with a Requisite dependency, systemd first checks the status of the dependency. If the dependency has not been activated, systemd fails on activation of the unit with the dependency. Conflicts. Negative dependencies. When activating a unit with a Conflict dependency, systemd automatically deactivates the dependency if it is active. Simultaneous activation of two conflicting units fails. View a unit’s dependencies 1systemctl show -p TYPE UNIT Ordering of unit Before. The current unit will activate before the listed unit(s). Before= foo.target bar.target After. The current unit activates after the listed unit(s). Conditional dependency Several dependency condition keywords operate on various operation system states. (e.g. ConditionPathExists) If you activate a unit that has a condition dependency as well as some other unit dependencies, systemd attempts to activate the unit dependencies regardless of whether the condition is true or false. systemd Configuration Directories for systemd configuration globally configured: /usr/lib/systemd/system Avoid making changes to the system unit directory. When given the choice between modifying something in /usr and /etc, always change /etc. local definitions: /etc/systemd/system check the current systemd configuration search path (including precedence): 1systemctl -p UnitPath show To see the system unit and configuration directories on your system, use the following commands: 12pkg-config systemd --variable=systemdsystemunitdirpkg-config systemd --variable=systemdsystemconfdir Unit Files Format 123456789[UNIT]Key=ValueKey=Value...[SECTION]Key=ValueKey=Value... The [Unit] section gives some details about the unit and contains description and dependency information. About Service: systemd.service(5) and systemd.exec(5) manual page Example - sshd.service 1234567891011121314151617[Unit]Description=OpenSSH DaemonAfter=network.target[Service]Type=notifyEnvironmentFile=-/etc/sysconfig/sshExecStartPre=/usr/sbin/sshd-gen-keys-startExecStartPre=/usr/sbin/sshd -t $SSHD_OPTSExecStart=/usr/sbin/sshd -D $SSHD_OPTSExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=alwaysTasksMax=infinity[Install]WantedBy=multi-user.target Enable Units and the [INSTALL] Section [Install]: a mechanism for enabling units without modifying any configuration files. When you enable a unit, systemd reads the [Install] section; in this case, enabling the sshd.service unit causes systemd to see the WantedBy dependency for multi-user.target. 12VM:/etc/systemd/system/multi-user.target.wants # l sshd*lrwxrwxrwx 1 root root 36 Oct 13 12:49 sshd.service -&gt; /usr/lib/systemd/system/sshd.service In response, systemd creates a symbolic link to sshd.service in the system configuration directory. The [Install] section is usually responsible for the the .wants and .requires directories in the system configuration directory (/etc/systemd/system). There are also .wants directories in the unit configuration directory (/usr/lib/systemd/system) A simple way to add a dependency (without modifying a unit file that may be overwritten) add links that don’t correspond to [Install] sections in the unit files. Enabling a unit When you enable a unit, you are installing it into systemd’s configuration, making semi-permanent changes that will survive a reboot. If the unit file has an [Install] section, you must enable it with systemctl enable; otherwise, the existence of the file is enough to enable it. systemctl start: Just turn the unit on in the current runtime environment. Enabling a unit does not activate the unit. Variables and Specifiers $OPTIONS: options that you can pass to service when you activate the unit with systemctl $MAINPID: the tracked process of the service A specifier is another variable-like feature. Specifiers start with a percent (%). E.g. %H: the current hostname %n: the current unit name You can parameterize a single unit file in order to spawn multiple copies of a service. To use these specifiers, add the @ symbol to the end of the unit name. 123456789101112131415VM:/usr/lib/systemd/system # l getty*-rw-r--r-- 1 root root 460 Jun 8 07:29 getty.target-rw-r--r-- 1 root root 1561 Jun 8 07:29 getty@.servicegetty@tty1.service.d:total 24drwxr-xr-x 2 root root 4096 Oct 13 12:47 ./drwxr-xr-x 29 root root 16384 Nov 18 07:32 ../-rw-r--r-- 1 root root 71 Jun 8 07:29 noclear.confVM:/etc/systemd/system/getty.target.wants # ltotal 8drwxr-xr-x 2 root root 4096 Oct 13 12:47 ./drwxr-xr-x 11 root root 4096 Oct 30 08:17 ../lrwxrwxrwx 1 root root 38 Oct 13 12:47 getty@tty1.service -&gt; /usr/lib/systemd/system/getty@.service Anything after the @ is called the instance, and when processing the unit file, systemd expands the %I specifier to the instance. You can see this in action with the getty@.service unit files that come with most distributions running systemd. systemd Operation - the systemctl command View a list of active units on your system, issue a list-units command (default of systemctl). To see the full names of the units, use the --full option. To see all units (not just active), use the --all option. status: getting the status of a unit. You can view the process tree of the control group without the rest of the unit status with the systemd-cgls command. Wiew a unit’s entire journal with this command: 1journalctl _SYSTEMD_UNIT=unit If you’ve changed a unit configuration file, you can tell systemd to reload the file in one of two ways: systemctl reload UNIT: Reloads just the configuration for UNIT. systemctl daemon-reload: Reloads all unit configurations. Requests to activate, reactivate, and restart units are known as jobs (unit state changes) in systemd. Check the current jobs (mostly at boot time) on a system with systemctl list-jobs. Although a systemd job associated with a unit will terminate, the unit itself can be active and running afterwards, especially in the case of service units. Adding Units to systemd Customized unit files: /etc/systemd/system. Simple Example: If your unit file has an [Install] section, “enable” the unit before activating it. Removing Units systemd Process Tracking and Synchronization systemd uses control groups (cgroups), an optional Linux kernel feature that allows for finer tracking of a process hierarchy. In systemd, you just care about whether it forks. Use the Type option in your service unit file to indicate its startup behavior. systemd On-Demand and Resource-Parallelized Startup essential boot-time service: syslog and dbus BOOT OPTIMIZATION WITH AUXILIARY UNITS When parallelizing startup, there is a chance that your system may slow down temporarily due to a large number of units starting at once.","link":"/2020/06/28/A-Big-Picture-of-Linux/"}],"tags":[{"name":"Process","slug":"Process","link":"/tags/Process/"},{"name":"Bash","slug":"Bash","link":"/tags/Bash/"},{"name":"Cheatsheet","slug":"Cheatsheet","link":"/tags/Cheatsheet/"},{"name":"Key Binding","slug":"Key-Binding","link":"/tags/Key-Binding/"},{"name":"Pattern Matching","slug":"Pattern-Matching","link":"/tags/Pattern-Matching/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Helm","slug":"Helm","link":"/tags/Helm/"},{"name":"K8s","slug":"K8s","link":"/tags/K8s/"},{"name":"man","slug":"man","link":"/tags/man/"},{"name":"GNU","slug":"GNU","link":"/tags/GNU/"},{"name":"cheatsheet","slug":"cheatsheet","link":"/tags/cheatsheet/"},{"name":"Dot Files","slug":"Dot-Files","link":"/tags/Dot-Files/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"Cloudflare","slug":"Cloudflare","link":"/tags/Cloudflare/"},{"name":"DNS","slug":"DNS","link":"/tags/DNS/"},{"name":"Ingress","slug":"Ingress","link":"/tags/Ingress/"},{"name":"Prometheous","slug":"Prometheous","link":"/tags/Prometheous/"},{"name":"I&#x2F;O","slug":"I-O","link":"/tags/I-O/"},{"name":"FHS","slug":"FHS","link":"/tags/FHS/"},{"name":"Command Line","slug":"Command-Line","link":"/tags/Command-Line/"}],"categories":[{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Cloud Native","slug":"Cloud-Native","link":"/categories/Cloud-Native/"},{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"Blog","slug":"Blog","link":"/categories/Blog/"},{"name":"Database","slug":"Cloud-Native/Database","link":"/categories/Cloud-Native/Database/"},{"name":"Productivity","slug":"Productivity","link":"/categories/Productivity/"},{"name":"Cloud Native","slug":"Database/Cloud-Native","link":"/categories/Database/Cloud-Native/"},{"name":"Event Monitoring and Alerting","slug":"Cloud-Native/Event-Monitoring-and-Alerting","link":"/categories/Cloud-Native/Event-Monitoring-and-Alerting/"}]}